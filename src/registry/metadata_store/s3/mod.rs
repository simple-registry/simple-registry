use std::sync::Arc;

use async_trait::async_trait;
use bytes::Bytes;
use serde::Deserialize;
use tracing::{debug, info, instrument};

use crate::oci::{Descriptor, Digest, Manifest};
use crate::registry::metadata_store::link_kind::LinkKind;
use crate::registry::metadata_store::lock::{self, LockBackend, MemoryBackend};
use crate::registry::metadata_store::{BlobIndex, Error};
use crate::registry::metadata_store::{
    BlobIndexOperation, LinkMetadata, LinkOperation, LockConfig, MetadataStore,
};
use crate::registry::{data_store, pagination, path_builder};

#[derive(Clone, Debug, Default, Deserialize, PartialEq)]
pub struct BackendConfig {
    pub access_key_id: String,
    pub secret_key: String,
    pub endpoint: String,
    pub bucket: String,
    pub region: String,
    #[serde(default)]
    pub key_prefix: String,
    #[serde(default)]
    pub redis: Option<LockConfig>,
}

impl From<BackendConfig> for data_store::s3::BackendConfig {
    fn from(config: BackendConfig) -> Self {
        Self {
            access_key_id: config.access_key_id,
            secret_key: config.secret_key,
            endpoint: config.endpoint,
            bucket: config.bucket,
            region: config.region,
            key_prefix: config.key_prefix,
            ..Default::default()
        }
    }
}

#[derive(Clone)]
pub struct Backend {
    pub store: data_store::s3::Backend,
    lock: Arc<dyn LockBackend<Guard = Box<dyn Send>> + Send + Sync>,
}

impl Backend {
    pub fn new(config: &BackendConfig) -> Result<Self, Error> {
        info!("Using S3 metadata-store backend");
        let store = data_store::s3::Backend::new(&data_store::s3::BackendConfig {
            access_key_id: config.access_key_id.clone(),
            secret_key: config.secret_key.clone(),
            endpoint: config.endpoint.clone(),
            bucket: config.bucket.clone(),
            region: config.region.clone(),
            key_prefix: config.key_prefix.clone(),
            ..Default::default()
        })?;

        let lock: Arc<dyn LockBackend<Guard = Box<dyn Send>> + Send + Sync> =
            if let Some(redis_config) = &config.redis {
                info!("Using Redis lock store for S3 metadata-store");
                let backend = lock::RedisBackend::new(redis_config).map_err(|e| {
                    Error::Lock(format!("Failed to initialize Redis lock store: {e}"))
                })?;
                Arc::new(backend)
            } else {
                info!("Using in-memory lock store for S3 metadata-store");
                Arc::new(MemoryBackend::new())
            };

        Ok(Self { store, lock })
    }
}

#[async_trait]
impl MetadataStore for Backend {
    #[instrument(skip(self))]
    async fn list_namespaces(
        &self,
        n: u16,
        last: Option<String>,
    ) -> Result<(Vec<String>, Option<String>), Error> {
        debug!("Fetching {n} namespace(s) with continuation token: {last:?}");

        // List all objects under the repository directory
        let repo_dir = path_builder::repository_dir();

        let mut namespaces = Vec::new();
        let mut continuation_token = None;

        // List all objects recursively to find all namespaces
        loop {
            let (objects, next_token) = self
                .store
                .list_objects(repo_dir, 1000, continuation_token)
                .await?;

            for key in objects {
                // The path is relative to v2/repositories, like:
                // namespace/_manifests/... or
                // namespace/nested/_manifests/...

                // Look for special directories that indicate a namespace
                for marker in &["/_manifests/", "/_layers/", "/_uploads/", "/_config/"] {
                    if let Some(idx) = key.find(marker) {
                        let namespace = key[..idx].to_string();
                        if !namespaces.contains(&namespace) {
                            namespaces.push(namespace);
                        }
                        break; // Found a namespace, no need to check other markers
                    }
                }
            }

            continuation_token = next_token;
            if continuation_token.is_none() {
                break;
            }
        }

        // Sort namespaces for consistent pagination
        namespaces.sort();

        Ok(pagination::paginate_sorted(&namespaces, n, last.as_deref()))
    }

    #[instrument(skip(self))]
    async fn list_tags(
        &self,
        namespace: &str,
        n: u16,
        last: Option<String>,
    ) -> Result<(Vec<String>, Option<String>), Error> {
        debug!(
            "Listing {n} tag(s) for namespace '{namespace}' starting with continuation_token '{last:?}'"
        );
        let tags_dir = path_builder::manifest_tags_dir(namespace);

        let mut all_tags = Vec::new();
        let mut continuation_token = None;

        loop {
            let (prefixes, _, next_token) = self
                .store
                .list_prefixes(&tags_dir, "/", 1000, continuation_token)
                .await?;

            all_tags.extend(prefixes);

            continuation_token = next_token;
            if continuation_token.is_none() {
                break;
            }
        }

        Ok(pagination::paginate_sorted(&all_tags, n, last.as_deref()))
    }

    #[instrument(skip(self))]
    async fn list_referrers(
        &self,
        namespace: &str,
        digest: &Digest,
        artifact_type: Option<String>,
    ) -> Result<Vec<Descriptor>, Error> {
        let referrers_dir = path_builder::manifest_referrers_dir(namespace, digest);

        let mut referrers = Vec::new();
        let mut continuation_token = None;

        loop {
            let (objects, next_token) = self
                .store
                .list_objects(&referrers_dir, 100, continuation_token)
                .await?;

            for key in objects {
                // The key is a relative path like "sha256/<digest>/link"
                let parts: Vec<&str> = key.split('/').collect();
                if parts.len() < 2 || parts[0] != "sha256" {
                    continue;
                }

                let manifest_digest = Digest::Sha256(parts[1].into());
                let blob_path = path_builder::blob_path(&manifest_digest);

                let manifest = match self.store.read(&blob_path).await {
                    Ok(data) => data,
                    Err(e) if e.kind() == std::io::ErrorKind::NotFound => {
                        return Err(Error::ReferenceNotFound);
                    }
                    Err(e) => return Err(e.into()),
                };
                let manifest_len = manifest.len();

                let manifest = Manifest::from_slice(&manifest)?;
                if let Some(descriptor) = manifest.to_descriptor(
                    artifact_type.as_ref(),
                    manifest_digest,
                    manifest_len as u64,
                ) {
                    referrers.push(descriptor);
                }
            }

            continuation_token = next_token;
            if continuation_token.is_none() {
                break;
            }
        }

        Ok(referrers)
    }

    async fn has_referrers(&self, namespace: &str, subject: &Digest) -> Result<bool, Error> {
        let referrers_dir = path_builder::manifest_referrers_dir(namespace, subject);

        let (objects, _) = self.store.list_objects(&referrers_dir, 1, None).await?;

        Ok(!objects.is_empty())
    }

    async fn list_revisions(
        &self,
        namespace: &str,
        n: u16,
        continuation_token: Option<String>,
    ) -> Result<(Vec<Digest>, Option<String>), Error> {
        debug!(
            "Fetching {n} revision(s) for namespace '{namespace}' with continuation token: {continuation_token:?}"
        );
        let revisions_dir = path_builder::manifest_revisions_link_root_dir(namespace, "sha256");

        let (prefixes, _, next_last) = self
            .store
            .list_prefixes(&revisions_dir, "/", i32::from(n), continuation_token)
            .await?;

        let mut revisions = Vec::new();
        for key in prefixes {
            revisions.push(Digest::Sha256(key.into()));
        }

        Ok((revisions, next_last))
    }

    async fn count_manifests(&self, namespace: &str) -> Result<usize, Error> {
        let revisions_dir = path_builder::manifest_revisions_link_root_dir(namespace, "sha256");
        let mut count = 0;
        let mut continuation_token = None;

        loop {
            let (prefixes, _, next_token) = self
                .store
                .list_prefixes(&revisions_dir, "/", 1000, continuation_token)
                .await?;

            count += prefixes.len();
            continuation_token = next_token;
            if continuation_token.is_none() {
                break;
            }
        }

        Ok(count)
    }

    #[instrument(skip(self))]
    async fn read_blob_index(&self, digest: &Digest) -> Result<BlobIndex, Error> {
        let path = path_builder::blob_index_path(digest);

        let data = match self.store.read(&path).await {
            Ok(data) => data,
            Err(e) if e.kind() == std::io::ErrorKind::NotFound => {
                return Err(Error::ReferenceNotFound);
            }
            Err(e) => return Err(e.into()),
        };
        let index = serde_json::from_slice(&data)?;

        Ok(index)
    }

    #[instrument(skip(self))]
    async fn update_blob_index(
        &self,
        namespace: &str,
        digest: &Digest,
        operation: BlobIndexOperation,
    ) -> Result<(), Error> {
        let path = path_builder::blob_index_path(digest);

        let mut reference_index = match self.store.read(&path).await {
            Ok(data) => serde_json::from_slice::<BlobIndex>(&data)?,
            Err(e) if e.kind() == std::io::ErrorKind::NotFound => BlobIndex::default(),
            Err(e) => return Err(e.into()),
        };

        let mut index = reference_index
            .namespace
            .remove(namespace)
            .unwrap_or_default();
        match operation {
            BlobIndexOperation::Insert(link) => {
                index.insert(link);
            }
            BlobIndexOperation::Remove(link) => {
                index.remove(&link);
            }
        }
        if !index.is_empty() {
            reference_index
                .namespace
                .insert(namespace.to_string(), index);
        }

        if reference_index.namespace.is_empty() {
            let path = path_builder::blob_container_dir(digest);
            self.store.delete_prefix(&path).await?;
        } else {
            let content = Bytes::from(serde_json::to_vec(&reference_index)?);
            self.store.put_object(&path, content).await?;
        }

        Ok(())
    }

    #[instrument(skip(self))]
    async fn read_link(
        &self,
        namespace: &str,
        link: &LinkKind,
        update_access_time: bool,
    ) -> Result<LinkMetadata, Error> {
        let _guard = self.lock.acquire(&[link.to_string()]).await?;

        if update_access_time {
            let link_data = self.read_link_reference(namespace, link).await?.accessed();
            self.write_link_reference(namespace, link, &link_data)
                .await?;
            Ok(link_data)
        } else {
            self.read_link_reference(namespace, link).await
        }
    }

    #[instrument(skip(self))]
    async fn update_links(
        &self,
        namespace: &str,
        operations: &[LinkOperation],
    ) -> Result<(), Error> {
        if operations.is_empty() {
            return Ok(());
        }

        loop {
            let mut lock_keys: Vec<String> = Vec::new();
            let mut creates: Vec<(LinkKind, Digest, Option<Digest>, Option<Digest>)> = Vec::new();
            let mut deletes: Vec<(LinkKind, Digest, Option<Digest>)> = Vec::new();

            for op in operations {
                match op {
                    LinkOperation::Create {
                        link,
                        target,
                        referrer,
                    } => {
                        lock_keys.push(link.to_string());
                        lock_keys.push(format!("blob:{target}"));
                        let old_target = self
                            .read_link_reference(namespace, link)
                            .await
                            .ok()
                            .map(|m| m.target);
                        if let Some(ref old) = old_target {
                            lock_keys.push(format!("blob:{old}"));
                        }
                        creates.push((link.clone(), target.clone(), old_target, referrer.clone()));
                    }
                    LinkOperation::Delete { link, referrer } => {
                        if let Ok(metadata) = self.read_link_reference(namespace, link).await {
                            lock_keys.push(link.to_string());
                            lock_keys.push(format!("blob:{}", metadata.target));
                            deletes.push((link.clone(), metadata.target, referrer.clone()));
                        }
                    }
                }
            }

            if creates.is_empty() && deletes.is_empty() {
                return Ok(());
            }

            lock_keys.sort();
            lock_keys.dedup();
            let _guard = self.lock.acquire(&lock_keys).await?;

            let mut needs_retry = false;
            for (link, _, expected_old, _) in &creates {
                let current = self
                    .read_link_reference(namespace, link)
                    .await
                    .ok()
                    .map(|m| m.target);
                if current != *expected_old {
                    needs_retry = true;
                    break;
                }
            }
            if needs_retry {
                continue;
            }

            let mut valid_deletes = Vec::new();
            for (link, target, referrer) in deletes {
                match self.read_link_reference(namespace, &link).await {
                    Ok(metadata) if metadata.target == target => {
                        valid_deletes.push((link, target, referrer));
                    }
                    Ok(_) => {
                        needs_retry = true;
                        break;
                    }
                    Err(Error::ReferenceNotFound) => {}
                    Err(e) => return Err(e),
                }
            }
            if needs_retry {
                continue;
            }

            for (link, target, old_target, referrer) in &creates {
                let is_tracked = is_tracked_link(link);

                if is_tracked && referrer.is_some() {
                    let mut metadata = self
                        .read_link_reference(namespace, link)
                        .await
                        .unwrap_or_else(|_| LinkMetadata::from_digest(target.clone()));

                    if let Some(manifest_digest) = referrer {
                        metadata.add_referrer(manifest_digest.clone());
                    }

                    if old_target.is_none() {
                        self.update_blob_index(
                            namespace,
                            target,
                            BlobIndexOperation::Insert(link.clone()),
                        )
                        .await?;
                    }

                    self.write_link_reference(namespace, link, &metadata)
                        .await?;
                } else {
                    self.update_blob_index(
                        namespace,
                        target,
                        BlobIndexOperation::Insert(link.clone()),
                    )
                    .await?;
                    if let Some(old) = old_target
                        && *old != *target
                    {
                        self.update_blob_index(
                            namespace,
                            old,
                            BlobIndexOperation::Remove(link.clone()),
                        )
                        .await?;
                    }

                    let metadata = LinkMetadata::from_digest(target.clone());
                    self.write_link_reference(namespace, link, &metadata)
                        .await?;
                }
            }

            for (link, target, referrer) in &valid_deletes {
                let is_tracked = is_tracked_link(link);

                if is_tracked && referrer.is_some() {
                    if let Ok(mut metadata) = self.read_link_reference(namespace, link).await {
                        if let Some(manifest_digest) = referrer {
                            metadata.remove_referrer(manifest_digest);
                        }

                        if metadata.has_references() {
                            self.write_link_reference(namespace, link, &metadata)
                                .await?;
                        } else {
                            self.delete_link_reference(namespace, link).await?;
                            self.update_blob_index(
                                namespace,
                                target,
                                BlobIndexOperation::Remove(link.clone()),
                            )
                            .await?;
                        }
                    }
                } else {
                    self.delete_link_reference(namespace, link).await?;
                    self.update_blob_index(
                        namespace,
                        target,
                        BlobIndexOperation::Remove(link.clone()),
                    )
                    .await?;
                }
            }

            return Ok(());
        }
    }
}

fn is_tracked_link(link: &LinkKind) -> bool {
    matches!(
        link,
        LinkKind::Layer(_) | LinkKind::Config(_) | LinkKind::Manifest(_, _)
    )
}

impl Backend {
    async fn read_link_reference(
        &self,
        namespace: &str,
        link: &LinkKind,
    ) -> Result<LinkMetadata, Error> {
        let link_path = path_builder::link_path(link, namespace);
        match self.store.read(&link_path).await {
            Ok(data) => LinkMetadata::from_bytes(data),
            Err(e) if e.kind() == std::io::ErrorKind::NotFound => Err(Error::ReferenceNotFound),
            Err(e) => Err(e.into()),
        }
    }

    async fn write_link_reference(
        &self,
        namespace: &str,
        link: &LinkKind,
        metadata: &LinkMetadata,
    ) -> Result<(), Error> {
        let link_path = path_builder::link_path(link, namespace);
        let serialized_link_data = Bytes::from(serde_json::to_vec(metadata)?);
        self.store
            .put_object(&link_path, serialized_link_data)
            .await?;
        Ok(())
    }

    async fn delete_link_reference(&self, namespace: &str, link: &LinkKind) -> Result<(), Error> {
        let link_path = path_builder::link_path(link, namespace);
        self.store.delete(&link_path).await?;
        Ok(())
    }
}
